{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho Computacional 3. Rede Convolucional e Transfer Learning\n",
    "\n",
    "## 1. Introdução e Base de Dados\n",
    "\n",
    "Neste trabalho usaremos uma rede convolucional pré-treinada e a aplicaremos em um problema novo. Também experimentaremos com a\n",
    "divisão da base em treinamento, validação e teste, e usaremos o conjunto de validação para a técnica \"early stopping\", na tentativa de controlar o sobre-ajuste.\n",
    "\n",
    "A base de dados é a [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Ela contém 60000 imagens 32x32 coloridas (3 canais) das seguintes categorias de objetos: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "\n",
    "Ela pode ser baixada com o código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "337cb9bac56348ecb28cf342cbf6b204",
      "efd38707eb0a4ac4b875626cd1f89eed",
      "ccd55a62cefb468c8a2483fd840744ad",
      "006e39be5baa48efa5f6a764794ac88a",
      "56a44b3f23a145599a1ead5f4863ae5a",
      "f2014973acc24cc0a2b740e53557f1b7",
      "1cfef9f82b7d49898c0e8ae5846d4f29",
      "89dc8b13a44748378faca300b8431842",
      "e7973d1aef464f82a1b24f67028f5720",
      "831cd354b1e940029462d8ca6bbbb2da",
      "522ff35e6a3b48789e4f907fa64c6267"
     ]
    },
    "executionInfo": {
     "elapsed": 14971,
     "status": "ok",
     "timestamp": 1699914359672,
     "user": {
      "displayName": "Alexandre Romariz",
      "userId": "08294063804806616136"
     },
     "user_tz": 180
    },
    "id": "Ef2uTTEXumSC",
    "outputId": "ba7d59ee-bfbe-46df-bc71-c915f27d5b57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 10000\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10():  #@save    \n",
    "    def __init__(self, root, resize=(224, 224)):    \n",
    "        trans = transforms.Compose([transforms.Resize(resize),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "        self.train = torchvision.datasets.CIFAR10(\n",
    "            root=root, train=True, transform=trans, download=True)\n",
    "        # use 20% of training data for validation\n",
    "        train_set_size = int(len(self.train) * 0.8)\n",
    "        valid_set_size = len(self.train) - train_set_size\n",
    "         # split the train set into two\n",
    "        seed = torch.Generator().manual_seed(42)\n",
    "        self.train, self.val = torch.utils.data.random_split(self.train, [train_set_size, valid_set_size], generator=seed)\n",
    "        self.test = torchvision.datasets.CIFAR10(\n",
    "            root=root, train=False, transform=trans, download=True)\n",
    "        \n",
    "dataset = CIFAR10(root=\"./data/\")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset.train, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset.val, batch_size=64, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset.test, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f\"Number of training examples: {len(dataset.train)}\")\n",
    "print(f\"Number of validation examples: {len(dataset.val)}\")\n",
    "print(f\"Number of test examples: {len(dataset.test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como foi feita a separação de 10.000 exemplos do conjunto de treinamento original para serem o conjunto de validação. Dessa forma, temos ao final 40.000 exemplos para treinamento, 10.000 exemplos para validação e 10.000 exemplos para teste, com os seus respectivos `DataLoader`'s instanciados.\n",
    "\n",
    "Também redimensionamos as imagens para 224x224pixels, já preparando o dado para a posterior aplicação na rede convolucional.\n",
    "\n",
    "## 2. Treinando um MLP\n",
    "\n",
    "Use esta base de dados para treinar um Perceptron Multicamadas, como feito no trabalho anterior com a base MNIST. Escolha um MLP com 2 camadas escondidas. Não perca muito tempo variando a arquitetura porque este problema é difícil sem o uso de convoluções e o resultado não será totalmente satisfatório.\n",
    "\n",
    "Você pode usar este código, baseado na biblioteca [Pytorch Lightning](https://lightning.ai/docs/pytorch/stable/) como base para definição da rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (44956469.py, line 39)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnn.Linear(3*224*224,?),\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-lightning\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# The model is passed as an argument to the `LightModel` class.\n",
    "class LightModel(pl.LightningModule):\n",
    "\tdef __init__(self,model,lr=1e-5):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.model = model\n",
    "\t\tself.lr = lr\n",
    "\tdef training_step(self, batch):\n",
    "\t\tX, y = batch\n",
    "\t\ty_hat = self.model(X)\n",
    "\t\tloss = nn.functional.cross_entropy(y_hat, y)\n",
    "\t\tself.log(\"train_loss\", loss)\n",
    "\t\treturn loss\n",
    "\tdef validation_step(self, batch):\n",
    "\t\tX, y = batch\n",
    "\t\ty_hat = self.model(X)\n",
    "\t\tloss = nn.functional.cross_entropy(y_hat, y)\n",
    "\t\tself.log(\"val_loss\", loss)\n",
    "\t\treturn loss\n",
    "\tdef test_step(self, batch):\n",
    "\t\tX, y = batch\n",
    "\t\ty_hat = self.model(X)\n",
    "\t\tpreds = torch.argmax(y_hat, dim=1)\n",
    "\t\tacc = accuracy(preds, y, task=\"multiclass\", num_classes=10)\n",
    "\t\tself.log(\"test_acc\", acc)\n",
    "\t\tloss = nn.functional.cross_entropy(y_hat, y)\t\t\n",
    "\t\tself.log(\"test_loss\", loss)\t\t\n",
    "\tdef configure_optimizers(self):\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), self.lr)\n",
    "\t\treturn optimizer\n",
    "\n",
    "\n",
    "arch = nn.Sequential(\n",
    "\t\t\tnn.Flatten(),\n",
    "\t\t\tnn.Linear(3*224*224,?),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(?,?),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(?,10)\t\n",
    "\t)\n",
    "\n",
    "mlp = LightModel(arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que as imagens são achatadas (transformadas em vetor). Substitua as interrogações pelo tamanho desejado das camadas\n",
    "escondidas.\n",
    "\n",
    "Neste problema vamos verificar o fenômeno do sobreajuste, e vamos tentar equilibrá-lo pela técnica de parada prematura de treinamento (early-stopping).\n",
    "Por isso foi necessário, a partir dos dados de treinamento, fazer uma nova separação para validação. Quando a função custo (`loss`) no conjunto de validação não diminui num dado número de épocas (o parâmetro `patience`), o treinamento é interrompido. Este trecho de código pode ser útil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # metric to monitor\n",
    "    patience=5,          # epochs with no improvement after which training will stop\n",
    "    mode='min',          # mode for min loss; 'max' if maximizing metric\n",
    "    min_delta=0.001      # minimum change to qualify as an improvement\n",
    ")\n",
    "\n",
    "trainer = Trainer(callbacks=[early_stopping], max_epochs=50)\n",
    "trainer.fit(model=mlp, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os parâmetros dados são sugestões. Você agora pode testar o seu modelo, por exemplo, com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "trainer.test(model=mlp, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, procure realizar ajustes, mas não espere um bom desempenho. Como dissemos, é um problema complexo de classificação de\n",
    "imagem, e é difícil fazer o MLP funcionar sozinho. Precisamos de um pré-processamento com base em uma rede convolucional.\n",
    "\n",
    "## 3. Uso da rede VGG16 pré-treinada\n",
    "\n",
    "Lembre-se que a rede VGG usa como bloco básico cascata de convoluções com filtros 3x3, com \"padding\" para que a imagem não seja\n",
    "diminuída, seguida de um \"max pooling\" reduzindo imagens pela metade. O número de mapas vai aumentando e seu tamanho vai diminuindo\n",
    "ao longo de suas 16 camadas. Este é um modelo gigantesco e o treinamento com recursos computacionais modestos levaria dias ou\n",
    "semanas, se é que fosse possível.\n",
    "\n",
    "No entanto, vamos aproveitar uma característica central das grandes redes convolucionais. Elas podem ser usadas como pré-processamento\n",
    "fixo das imagens, mesmo em um novo problema (lembre-se, a rede VGG original foi treinada na base ImageNet, que tem muitas categorias de\n",
    "imagens).\n",
    "\n",
    "O código abaixo realiza o download do modelo treinado e configura os seus parâmetros como não ajustáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5712,
     "status": "ok",
     "timestamp": 1699914381473,
     "user": {
      "displayName": "Alexandre Romariz",
      "userId": "08294063804806616136"
     },
     "user_tz": 180
    },
    "id": "WP-b_vl6wH0n",
    "outputId": "9714941f-823b-4d1c-e16a-63bec1ca3bcb"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "vgg16_model = vgg16(weights=\"DEFAULT\", progress=True)\n",
    "\n",
    "for param in vgg16_model.parameters():\n",
    "\tparam.requires_grad = False\n",
    "\n",
    "print(vgg16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, modifique o bloco de classificação (`vgg16_model.classifier`) da VGG16 de forma que fique semelhante ao MLP anterior, para trabalhar com somente 10 classes. Especifique uma camada `Flatten` (o MLP espera um vetor de entradas), e duas camadas densas. Elas não precisam ser muito grandes. Experimente com 50 e 20 neurônios, respectivamente, ou algo próximo.\n",
    "\n",
    "Volte a treinar e testar o modelo (pode usar as classes `LightModel` e `Trainer`). Mesmo sem efetivamente treinar toda a rede VGG (somente os parâmetros do bloco de classificação), ainda temos que passar os dados por ela a cada passo, e o treinamento é um tanto lento. Mas desta vez o problema deve ser resolvido satisfatoriamente.\n",
    "\n",
    "## 4. Extras (opcionais)\n",
    "\n",
    "### 4.1. Procure usar outra(s) redes convolucionais como base.\n",
    "### 4.2. No lugar de \"early stopping\", experimente com regularização L1 e L2, e \"dropout\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyME48Gv3/ej0y2TyzIHwS+K",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "006e39be5baa48efa5f6a764794ac88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_831cd354b1e940029462d8ca6bbbb2da",
      "placeholder": "​",
      "style": "IPY_MODEL_522ff35e6a3b48789e4f907fa64c6267",
      "value": " 5/5 [00:02&lt;00:00,  1.75 file/s]"
     }
    },
    "1cfef9f82b7d49898c0e8ae5846d4f29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "337cb9bac56348ecb28cf342cbf6b204": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efd38707eb0a4ac4b875626cd1f89eed",
       "IPY_MODEL_ccd55a62cefb468c8a2483fd840744ad",
       "IPY_MODEL_006e39be5baa48efa5f6a764794ac88a"
      ],
      "layout": "IPY_MODEL_56a44b3f23a145599a1ead5f4863ae5a"
     }
    },
    "522ff35e6a3b48789e4f907fa64c6267": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56a44b3f23a145599a1ead5f4863ae5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "831cd354b1e940029462d8ca6bbbb2da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89dc8b13a44748378faca300b8431842": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd55a62cefb468c8a2483fd840744ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89dc8b13a44748378faca300b8431842",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7973d1aef464f82a1b24f67028f5720",
      "value": 5
     }
    },
    "e7973d1aef464f82a1b24f67028f5720": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efd38707eb0a4ac4b875626cd1f89eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2014973acc24cc0a2b740e53557f1b7",
      "placeholder": "​",
      "style": "IPY_MODEL_1cfef9f82b7d49898c0e8ae5846d4f29",
      "value": "Dl Completed...: 100%"
     }
    },
    "f2014973acc24cc0a2b740e53557f1b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
